# -*- coding: utf-8 -*-
"""(2)VIT_Solo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vb547SWM5QURBI4PKfndM11qyAZ_wNVt
"""



import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from google.colab import drive
drive.mount('/content/drive')

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = datasets.ImageFolder("/content/drive/MyDrive/ISIC2016 original/train", transform=transform)
test_dataset = datasets.ImageFolder("/content/drive/MyDrive/ISIC2016 original/test", transform=transform)

device = "cuda" if torch.cuda.is_available() else "cpu"
device

# model_mobilenetV2 = models.mobilenet_v2(pretrained=True)
# model_DenseNet201 = models.densenet201(pretrained=True)
model_ViT = models.vit_b_16(pretrained=True)

num_classes = 2
# model_mobilenetV2.classifier[1] = nn.Linear(model_mobilenetV2.classifier[1].in_features, num_classes)
# print(model_mobilenetV2.classifier[1].in_features)
# model_DenseNet201.classifier = nn.Linear(model_DenseNet201.classifier.in_features, num_classes)
model_ViT.heads = nn.Linear(768, num_classes)  # Adjust the dimensions based on the ViT model

import torch.nn as nn

# Freeze the parameters in the Vision Transformer model
for parameter in model_ViT.parameters():
    parameter.requires_grad = False

# Assuming the ViT model's classification head is named 'heads'
num_features = model_ViT.heads.in_features

# Replace the classification head with a custom sequence of layers
model_ViT.heads = nn.Sequential(
    nn.Linear(num_features, 512),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(512, 2)
)

# Move the model to the device (GPU or CPU)
model_ViT.to(device)

!pip install torchinfo

from torchinfo import summary

summary(model=model_ViT,
        input_size=(32, 3, 224, 224),
        col_names=["input_size", "output_size", "num_params", "trainable"],
        col_width=20,
        row_settings=["var_names"])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

import time
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import numpy as np

def train_model(model_ViT, train_loader, criterion, optimizer, num_epochs):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model_ViT.to(device)

    for epoch in range(num_epochs):
        model_ViT.train()
        running_loss = 0.0
        correct = 0
        total = 0

        # Wrap the train_loader with tqdm for a progress bar
        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')

        for inputs, labels in progress_bar:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model_ViT(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            # Update the progress bar description
            progress_bar.set_description(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/total:.4f}, Acc: {100*correct/total:.2f}%')

        epoch_loss = running_loss / len(train_loader)
        epoch_acc = 100 * correct / total
        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')

    print('Finished Training')

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def evaluate_model(model_ViT, test_loader, device):
    model_ViT.eval()
    true_labels = []
    predicted_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model_ViT(inputs)
            _, predicted = torch.max(outputs, 1)
            true_labels.extend(labels.cpu().numpy())
            predicted_labels.extend(predicted.cpu().numpy())

    # Calculate metrics
    accuracy = accuracy_score(true_labels, predicted_labels)
    precision = precision_score(true_labels, predicted_labels, average='weighted')
    recall = recall_score(true_labels, predicted_labels, average='weighted')
    f1 = f1_score(true_labels, predicted_labels, average='weighted')

    # Calculate confusion matrix
    cm = confusion_matrix(true_labels, predicted_labels)

    return accuracy, precision, recall, f1, cm

def plot_confusion_matrix(cm, title='Confusion Matrix'):
    # plt.figure(figsize=(8, 6))
    # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    # plt.title(title)
    # plt.xlabel('Predicted Label')
    # plt.ylabel('True Label')
    # plt.show()
    group_names = ['True Positive (TP)', 'False Negative (FN)',
               'False Positive (FP)', 'True Negative (TN)']
    group_counts = ["{0:0.0f}".format(value) for value in cm.flatten()]
    group_percentages = ["{0:.2%}".format(value) for value in cm.flatten()/np.sum(cm)]
    labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]
    labels = np.asarray(labels).reshape(2,2)

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.show()

# Example for model_ViT
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_ViT.parameters(), lr=0.0001)

train_model(model_ViT, train_loader, criterion, optimizer, num_epochs=20)

import numpy as np
# Example for model_ViT
accuracy, precision, recall, f1, cm = evaluate_model(model_ViT, test_loader, device)
print(f'model_ViT - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}')
plot_confusion_matrix(cm, 'Confusion Matrix for model_ViT')

torch.save(model_ViT,'/content/drive/MyDrive/Models_Project2/model_ViT.pth')